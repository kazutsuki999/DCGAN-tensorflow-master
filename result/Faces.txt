yoshiharunoMacBook-Pro:DCGAN-tensorflow-master yoshiharu$ python main.py --dataset Faces --input_height=64 --output_height=64 --train
/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.
  from ._conv import register_converters as _register_converters
{'batch_size': <absl.flags._flag.Flag object at 0x10ad78630>,
 'beta1': <absl.flags._flag.Flag object at 0x10ad68f60>,
 'checkpoint_dir': <absl.flags._flag.Flag object at 0x1c1ee900b8>,
 'crop': <absl.flags._flag.BooleanFlag object at 0x1c1ee90278>,
 'data_dir': <absl.flags._flag.Flag object at 0x1c1ee90128>,
 'dataset': <absl.flags._flag.Flag object at 0x1c1ee88f60>,
 'epoch': <absl.flags._flag.Flag object at 0x102c25e10>,
 'generate_test_images': <absl.flags._flag.Flag object at 0x1c1ee90390>,
 'h': <tensorflow.python.platform.app._HelpFlag object at 0x1c1ee903c8>,
 'help': <tensorflow.python.platform.app._HelpFlag object at 0x1c1ee903c8>,
 'helpfull': <tensorflow.python.platform.app._HelpfullFlag object at 0x1c1ee90470>,
 'helpshort': <tensorflow.python.platform.app._HelpshortFlag object at 0x1c1ee904e0>,
 'input_fname_pattern': <absl.flags._flag.Flag object at 0x1c1ee88fd0>,
 'input_height': <absl.flags._flag.Flag object at 0x1c1ee24b70>,
 'input_width': <absl.flags._flag.Flag object at 0x1c1ee88da0>,
 'learning_rate': <absl.flags._flag.Flag object at 0x1053d2ef0>,
 'output_height': <absl.flags._flag.Flag object at 0x1c1ee88e48>,
 'output_width': <absl.flags._flag.Flag object at 0x1c1ee88ef0>,
 'sample_dir': <absl.flags._flag.Flag object at 0x1c1ee90198>,
 'train': <absl.flags._flag.BooleanFlag object at 0x1c1ee901d0>,
 'train_size': <absl.flags._flag.Flag object at 0x10ad78588>,
 'visualize': <absl.flags._flag.BooleanFlag object at 0x1c1ee902e8>}
2018-06-12 16:25:04.554417: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
---------
Variables: name (type shape) [size]
---------
generator/g_h0_lin/Matrix:0 (float32_ref 100x8192) [819200, bytes: 3276800]
generator/g_h0_lin/bias:0 (float32_ref 8192) [8192, bytes: 32768]
generator/g_bn0/beta:0 (float32_ref 512) [512, bytes: 2048]
generator/g_bn0/gamma:0 (float32_ref 512) [512, bytes: 2048]
generator/g_h1/w:0 (float32_ref 5x5x256x512) [3276800, bytes: 13107200]
generator/g_h1/biases:0 (float32_ref 256) [256, bytes: 1024]
generator/g_bn1/beta:0 (float32_ref 256) [256, bytes: 1024]
generator/g_bn1/gamma:0 (float32_ref 256) [256, bytes: 1024]
generator/g_h2/w:0 (float32_ref 5x5x128x256) [819200, bytes: 3276800]
generator/g_h2/biases:0 (float32_ref 128) [128, bytes: 512]
generator/g_bn2/beta:0 (float32_ref 128) [128, bytes: 512]
generator/g_bn2/gamma:0 (float32_ref 128) [128, bytes: 512]
generator/g_h3/w:0 (float32_ref 5x5x64x128) [204800, bytes: 819200]
generator/g_h3/biases:0 (float32_ref 64) [64, bytes: 256]
generator/g_bn3/beta:0 (float32_ref 64) [64, bytes: 256]
generator/g_bn3/gamma:0 (float32_ref 64) [64, bytes: 256]
generator/g_h4/w:0 (float32_ref 5x5x3x64) [4800, bytes: 19200]
generator/g_h4/biases:0 (float32_ref 3) [3, bytes: 12]
discriminator/d_h0_conv/w:0 (float32_ref 5x5x3x64) [4800, bytes: 19200]
discriminator/d_h0_conv/biases:0 (float32_ref 64) [64, bytes: 256]
discriminator/d_h1_conv/w:0 (float32_ref 5x5x64x128) [204800, bytes: 819200]
discriminator/d_h1_conv/biases:0 (float32_ref 128) [128, bytes: 512]
discriminator/d_bn1/beta:0 (float32_ref 128) [128, bytes: 512]
discriminator/d_bn1/gamma:0 (float32_ref 128) [128, bytes: 512]
discriminator/d_h2_conv/w:0 (float32_ref 5x5x128x256) [819200, bytes: 3276800]
discriminator/d_h2_conv/biases:0 (float32_ref 256) [256, bytes: 1024]
discriminator/d_bn2/beta:0 (float32_ref 256) [256, bytes: 1024]
discriminator/d_bn2/gamma:0 (float32_ref 256) [256, bytes: 1024]
discriminator/d_h3_conv/w:0 (float32_ref 5x5x256x512) [3276800, bytes: 13107200]
discriminator/d_h3_conv/biases:0 (float32_ref 512) [512, bytes: 2048]
discriminator/d_bn3/beta:0 (float32_ref 512) [512, bytes: 2048]
discriminator/d_bn3/gamma:0 (float32_ref 512) [512, bytes: 2048]
discriminator/d_h4_lin/Matrix:0 (float32_ref 8192x1) [8192, bytes: 32768]
discriminator/d_h4_lin/bias:0 (float32_ref 1) [1, bytes: 4]
Total size of variables: 9451908
Total bytes of variables: 37807632
 [*] Reading checkpoints...
 [*] Failed to find a checkpoint
 [!] Load failed...
Epoch: [ 0/25] [   0/   6] time: 13.1758, d_loss: 7.02400160, g_loss: 0.00120019
Epoch: [ 0/25] [   1/   6] time: 25.8886, d_loss: 6.95943785, g_loss: 0.00202379
Epoch: [ 0/25] [   2/   6] time: 38.6222, d_loss: 7.15925837, g_loss: 0.00207817
Epoch: [ 0/25] [   3/   6] time: 51.9538, d_loss: 7.49812555, g_loss: 0.00198032
Epoch: [ 0/25] [   4/   6] time: 65.4212, d_loss: 7.40278912, g_loss: 0.00362786
Epoch: [ 0/25] [   5/   6] time: 78.9205, d_loss: 5.86778641, g_loss: 0.01627034
Epoch: [ 1/25] [   0/   6] time: 91.9004, d_loss: 7.96431160, g_loss: 0.00164778
Epoch: [ 1/25] [   1/   6] time: 106.3409, d_loss: 4.52875662, g_loss: 0.05639984
Epoch: [ 1/25] [   2/   6] time: 121.0862, d_loss: 5.35215282, g_loss: 0.04286627
Epoch: [ 1/25] [   3/   6] time: 134.1512, d_loss: 7.28525352, g_loss: 0.00978518
Epoch: [ 1/25] [   4/   6] time: 147.1415, d_loss: 3.55676889, g_loss: 0.41600603
Epoch: [ 1/25] [   5/   6] time: 160.1729, d_loss: 8.74399567, g_loss: 0.00095485
Epoch: [ 2/25] [   0/   6] time: 173.0465, d_loss: 2.69433546, g_loss: 0.83300704
Epoch: [ 2/25] [   1/   6] time: 185.8392, d_loss: 9.31581116, g_loss: 0.00040369
Epoch: [ 2/25] [   2/   6] time: 198.7688, d_loss: 2.32486463, g_loss: 0.66381490
Epoch: [ 2/25] [   3/   6] time: 211.6441, d_loss: 6.64767933, g_loss: 0.00598046
Epoch: [ 2/25] [   4/   6] time: 224.4479, d_loss: 1.92305839, g_loss: 4.12862825
Epoch: [ 2/25] [   5/   6] time: 237.3349, d_loss: 6.39563131, g_loss: 0.00732659
Epoch: [ 3/25] [   0/   6] time: 250.2359, d_loss: 1.41961491, g_loss: 5.21156693
Epoch: [ 3/25] [   1/   6] time: 263.2403, d_loss: 5.07299137, g_loss: 0.02129089
Epoch: [ 3/25] [   2/   6] time: 276.1124, d_loss: 1.37149239, g_loss: 3.27396631
Epoch: [ 3/25] [   3/   6] time: 288.7217, d_loss: 9.47877502, g_loss: 0.00024589
Epoch: [ 3/25] [   4/   6] time: 301.5078, d_loss: 2.08320260, g_loss: 3.76734757
Epoch: [ 3/25] [   5/   6] time: 314.5984, d_loss: 5.59659433, g_loss: 0.01156849
Epoch: [ 4/25] [   0/   6] time: 327.3198, d_loss: 1.57934010, g_loss: 8.77047157
Epoch: [ 4/25] [   1/   6] time: 340.3205, d_loss: 1.33707380, g_loss: 2.37411976
Epoch: [ 4/25] [   2/   6] time: 353.3507, d_loss: 6.43843174, g_loss: 0.00340964
Epoch: [ 4/25] [   3/   6] time: 366.2255, d_loss: 0.77443475, g_loss: 8.03831291
Epoch: [ 4/25] [   4/   6] time: 379.2431, d_loss: 5.69679832, g_loss: 0.01019964
Epoch: [ 4/25] [   5/   6] time: 391.9011, d_loss: 1.61793363, g_loss: 6.04794359
Epoch: [ 5/25] [   0/   6] time: 404.6189, d_loss: 3.22464991, g_loss: 0.12794685
Epoch: [ 5/25] [   1/   6] time: 417.7450, d_loss: 1.82391369, g_loss: 7.12707806
Epoch: [ 5/25] [   2/   6] time: 431.7095, d_loss: 1.77823555, g_loss: 0.32824540
Epoch: [ 5/25] [   3/   6] time: 445.2621, d_loss: 1.27867186, g_loss: 3.18039560
Epoch: [ 5/25] [   4/   6] time: 458.2386, d_loss: 6.01856136, g_loss: 0.00877321
Epoch: [ 5/25] [   5/   6] time: 471.2451, d_loss: 1.28935468, g_loss: 7.35505342
Epoch: [ 6/25] [   0/   6] time: 484.2698, d_loss: 4.47573519, g_loss: 0.04258806
Epoch: [ 6/25] [   1/   6] time: 497.6202, d_loss: 1.84554124, g_loss: 8.36580467
Epoch: [ 6/25] [   2/   6] time: 510.2860, d_loss: 1.79168606, g_loss: 0.87523413
Epoch: [ 6/25] [   3/   6] time: 523.5015, d_loss: 7.54213142, g_loss: 0.00227472
Epoch: [ 6/25] [   4/   6] time: 536.2371, d_loss: 3.16014647, g_loss: 2.25599575
Epoch: [ 6/25] [   5/   6] time: 548.4459, d_loss: 7.89641476, g_loss: 0.00251617
Epoch: [ 7/25] [   0/   6] time: 562.4633, d_loss: 3.88961458, g_loss: 5.09371948
Epoch: [ 7/25] [   1/   6] time: 576.6022, d_loss: 4.75754166, g_loss: 0.06182404
Epoch: [ 7/25] [   2/   6] time: 590.7555, d_loss: 3.19687557, g_loss: 5.92145729
Epoch: [ 7/25] [   3/   6] time: 609.2384, d_loss: 1.70139956, g_loss: 1.38886559
Epoch: [ 7/25] [   4/   6] time: 623.1912, d_loss: 3.64984798, g_loss: 0.07340164
Epoch: [ 7/25] [   5/   6] time: 636.7958, d_loss: 1.60277832, g_loss: 8.90863991
Epoch: [ 8/25] [   0/   6] time: 649.9166, d_loss: 1.26132953, g_loss: 4.01178026
Epoch: [ 8/25] [   1/   6] time: 662.8036, d_loss: 3.90219212, g_loss: 0.04586938
Epoch: [ 8/25] [   2/   6] time: 675.8357, d_loss: 1.32194495, g_loss: 7.00007200
Epoch: [ 8/25] [   3/   6] time: 688.7860, d_loss: 0.85510635, g_loss: 3.99140120
Epoch: [ 8/25] [   4/   6] time: 700.8683, d_loss: 2.91405249, g_loss: 0.09160480
Epoch: [ 8/25] [   5/   6] time: 712.4614, d_loss: 0.98418474, g_loss: 9.00053978
Epoch: [ 9/25] [   0/   6] time: 724.7848, d_loss: 0.49638408, g_loss: 8.30252647
Epoch: [ 9/25] [   1/   6] time: 737.8149, d_loss: 1.43560219, g_loss: 0.48879504
Epoch: [ 9/25] [   2/   6] time: 751.0694, d_loss: 7.02210903, g_loss: 0.00482793
Epoch: [ 9/25] [   3/   6] time: 763.8946, d_loss: 2.69620538, g_loss: 1.25640416
Epoch: [ 9/25] [   4/   6] time: 776.9733, d_loss: 4.31920528, g_loss: 0.14621031
Epoch: [ 9/25] [   5/   6] time: 790.0995, d_loss: 3.40371656, g_loss: 5.32987118
Epoch: [10/25] [   0/   6] time: 803.1584, d_loss: 4.52669382, g_loss: 0.09015233
Epoch: [10/25] [   1/   6] time: 816.0366, d_loss: 2.20945430, g_loss: 4.05420256
Epoch: [10/25] [   2/   6] time: 828.5355, d_loss: 2.09636378, g_loss: 0.68829817
Epoch: [10/25] [   3/   6] time: 840.5364, d_loss: 1.83797002, g_loss: 0.75244772
Epoch: [10/25] [   4/   6] time: 852.7649, d_loss: 1.52411246, g_loss: 1.65393281
Epoch: [10/25] [   5/   6] time: 866.2239, d_loss: 1.56595135, g_loss: 0.69781458
Epoch: [11/25] [   0/   6] time: 880.1729, d_loss: 1.43358338, g_loss: 2.56544423
Epoch: [11/25] [   1/   6] time: 893.6597, d_loss: 1.08411956, g_loss: 1.37967288
Epoch: [11/25] [   2/   6] time: 907.5582, d_loss: 1.02997458, g_loss: 1.02880168
Epoch: [11/25] [   3/   6] time: 920.5056, d_loss: 0.46329504, g_loss: 3.03450751
Epoch: [11/25] [   4/   6] time: 933.5107, d_loss: 0.37859651, g_loss: 1.77907133
Epoch: [11/25] [   5/   6] time: 946.3203, d_loss: 1.80960250, g_loss: 0.30887482
Epoch: [12/25] [   0/   6] time: 959.7995, d_loss: 0.96811670, g_loss: 3.44881129
Epoch: [12/25] [   1/   6] time: 974.9837, d_loss: 1.43309569, g_loss: 0.76099503
Epoch: [12/25] [   2/   6] time: 988.2396, d_loss: 0.80679309, g_loss: 3.30423546
Epoch: [12/25] [   3/   6] time: 1003.9819, d_loss: 1.45745873, g_loss: 0.76381969
Epoch: [12/25] [   4/   6] time: 1016.4534, d_loss: 2.56029749, g_loss: 0.17006472
Epoch: [12/25] [   5/   6] time: 1031.1821, d_loss: 2.33158350, g_loss: 0.69244015
Epoch: [13/25] [   0/   6] time: 1045.0618, d_loss: 3.86846256, g_loss: 0.21368524
Epoch: [13/25] [   1/   6] time: 1059.2564, d_loss: 2.42010665, g_loss: 5.00219297
Epoch: [13/25] [   2/   6] time: 1072.2652, d_loss: 2.60285115, g_loss: 0.27346927
Epoch: [13/25] [   3/   6] time: 1084.9323, d_loss: 1.21955585, g_loss: 4.36933517
Epoch: [13/25] [   4/   6] time: 1097.1081, d_loss: 1.11268997, g_loss: 2.48818421
Epoch: [13/25] [   5/   6] time: 1109.1100, d_loss: 1.49707270, g_loss: 0.46764815
Epoch: [14/25] [   0/   6] time: 1120.9865, d_loss: 0.75541645, g_loss: 4.52126217
Epoch: [14/25] [   1/   6] time: 1132.7530, d_loss: 3.00358534, g_loss: 0.21347651
Epoch: [14/25] [   2/   6] time: 1144.6680, d_loss: 2.62466526, g_loss: 0.34381869
Epoch: [14/25] [   3/   6] time: 1156.6464, d_loss: 2.42173696, g_loss: 1.21563983
Epoch: [14/25] [   4/   6] time: 1168.5674, d_loss: 2.58464622, g_loss: 0.32906485
Epoch: [14/25] [   5/   6] time: 1180.3364, d_loss: 1.91803634, g_loss: 2.91067982
Epoch: [15/25] [   0/   6] time: 1192.2925, d_loss: 0.94648808, g_loss: 1.48225236
Epoch: [15/25] [   1/   6] time: 1204.2516, d_loss: 1.30152273, g_loss: 0.58138967
Epoch: [15/25] [   2/   6] time: 1215.8610, d_loss: 1.06479931, g_loss: 1.47949803
Epoch: [15/25] [   3/   6] time: 1227.8114, d_loss: 1.93948400, g_loss: 0.59228265
Epoch: [15/25] [   4/   6] time: 1239.9213, d_loss: 2.07569814, g_loss: 0.83395648
Epoch: [15/25] [   5/   6] time: 1251.8040, d_loss: 1.66509044, g_loss: 1.13796186
Epoch: [16/25] [   0/   6] time: 1263.8261, d_loss: 1.39287114, g_loss: 0.90123081
Epoch: [16/25] [   1/   6] time: 1275.9815, d_loss: 1.64766109, g_loss: 0.73075390
Epoch: [16/25] [   2/   6] time: 1287.7176, d_loss: 1.68673909, g_loss: 1.03976166
Epoch: [16/25] [   3/   6] time: 1299.8281, d_loss: 1.24698138, g_loss: 1.17265868
[Sample] d_loss: 0.85721666, g_loss: 1.70285439
Epoch: [16/25] [   4/   6] time: 1313.6401, d_loss: 1.14604664, g_loss: 1.02129865
Epoch: [16/25] [   5/   6] time: 1325.7357, d_loss: 1.02018332, g_loss: 1.01084590
Epoch: [17/25] [   0/   6] time: 1337.9053, d_loss: 1.49951434, g_loss: 0.69651306
Epoch: [17/25] [   1/   6] time: 1349.8419, d_loss: 1.74270225, g_loss: 0.61855072
Epoch: [17/25] [   2/   6] time: 1361.7583, d_loss: 2.23681235, g_loss: 0.60440552
Epoch: [17/25] [   3/   6] time: 1373.4284, d_loss: 2.08155823, g_loss: 0.74087167
Epoch: [17/25] [   4/   6] time: 1385.3970, d_loss: 1.79477179, g_loss: 0.49243551
Epoch: [17/25] [   5/   6] time: 1397.2372, d_loss: 1.59114885, g_loss: 0.77966923
Epoch: [18/25] [   0/   6] time: 1408.8369, d_loss: 1.20530653, g_loss: 0.99137610
Epoch: [18/25] [   1/   6] time: 1420.5476, d_loss: 1.79061007, g_loss: 0.64602542
Epoch: [18/25] [   2/   6] time: 1432.1993, d_loss: 1.17102575, g_loss: 0.82665515
Epoch: [18/25] [   3/   6] time: 1443.8732, d_loss: 1.54064894, g_loss: 0.67364621
Epoch: [18/25] [   4/   6] time: 1454.7938, d_loss: 2.17723513, g_loss: 0.34945089
Epoch: [18/25] [   5/   6] time: 1466.4033, d_loss: 2.49118209, g_loss: 0.47013596
Epoch: [19/25] [   0/   6] time: 1478.7358, d_loss: 2.04524684, g_loss: 0.80795610
Epoch: [19/25] [   1/   6] time: 1491.0160, d_loss: 1.78384078, g_loss: 0.75874984
Epoch: [19/25] [   2/   6] time: 1502.7746, d_loss: 1.63421953, g_loss: 0.60542268
Epoch: [19/25] [   3/   6] time: 1513.4999, d_loss: 1.14326000, g_loss: 1.25809634
Epoch: [19/25] [   4/   6] time: 1523.9881, d_loss: 1.41520524, g_loss: 0.63554257
Epoch: [19/25] [   5/   6] time: 1536.4396, d_loss: 1.63451481, g_loss: 0.60679889
Epoch: [20/25] [   0/   6] time: 1548.5439, d_loss: 1.62051308, g_loss: 0.62001634
Epoch: [20/25] [   1/   6] time: 1560.4011, d_loss: 1.62173975, g_loss: 0.66302550
Epoch: [20/25] [   2/   6] time: 1572.0897, d_loss: 1.52373207, g_loss: 0.71473324
Epoch: [20/25] [   3/   6] time: 1584.0190, d_loss: 1.61345553, g_loss: 0.59739172
Epoch: [20/25] [   4/   6] time: 1596.0147, d_loss: 1.22581863, g_loss: 1.13815260
Epoch: [20/25] [   5/   6] time: 1608.1391, d_loss: 1.21214652, g_loss: 1.00176322
Epoch: [21/25] [   0/   6] time: 1623.1619, d_loss: 1.05262709, g_loss: 0.83414507
Epoch: [21/25] [   1/   6] time: 1635.9580, d_loss: 1.25162935, g_loss: 0.68202269
Epoch: [21/25] [   2/   6] time: 1649.8133, d_loss: 1.36096025, g_loss: 0.67735696
Epoch: [21/25] [   3/   6] time: 1661.8172, d_loss: 1.69153833, g_loss: 0.69133425
Epoch: [21/25] [   4/   6] time: 1674.4956, d_loss: 1.76521266, g_loss: 0.70716345
Epoch: [21/25] [   5/   6] time: 1686.4606, d_loss: 1.43528152, g_loss: 1.13814306
Epoch: [22/25] [   0/   6] time: 1698.4718, d_loss: 1.35635459, g_loss: 0.67335618
Epoch: [22/25] [   1/   6] time: 1710.6210, d_loss: 1.59210396, g_loss: 0.65870571
Epoch: [22/25] [   2/   6] time: 1722.7599, d_loss: 2.04072452, g_loss: 0.52787256
Epoch: [22/25] [   3/   6] time: 1734.8642, d_loss: 1.99107337, g_loss: 0.55257547
Epoch: [22/25] [   4/   6] time: 1746.3604, d_loss: 1.88621080, g_loss: 0.55682218
Epoch: [22/25] [   5/   6] time: 1757.8172, d_loss: 1.69159555, g_loss: 0.76527375
Epoch: [23/25] [   0/   6] time: 1770.1080, d_loss: 1.34141850, g_loss: 1.04404354
Epoch: [23/25] [   1/   6] time: 1783.3997, d_loss: 1.42734301, g_loss: 0.61423850
Epoch: [23/25] [   2/   6] time: 1795.9158, d_loss: 1.25802946, g_loss: 0.98701614
Epoch: [23/25] [   3/   6] time: 1808.1465, d_loss: 1.70914626, g_loss: 0.48194247
Epoch: [23/25] [   4/   6] time: 1820.3048, d_loss: 1.62137938, g_loss: 0.60804999
Epoch: [23/25] [   5/   6] time: 1831.8097, d_loss: 1.20001221, g_loss: 1.69108689
Epoch: [24/25] [   0/   6] time: 1843.8830, d_loss: 1.37188721, g_loss: 0.69197023
Epoch: [24/25] [   1/   6] time: 1856.3150, d_loss: 1.26499319, g_loss: 0.70968187
Epoch: [24/25] [   2/   6] time: 1868.4248, d_loss: 1.59121609, g_loss: 0.59230185
Epoch: [24/25] [   3/   6] time: 1880.5451, d_loss: 1.69645953, g_loss: 0.68524730
Epoch: [24/25] [   4/   6] time: 1892.3351, d_loss: 1.97564340, g_loss: 0.57873529
Epoch: [24/25] [   5/   6] time: 1903.3320, d_loss: 1.75843906, g_loss: 0.63739687
 [*] 0
 [*] 1
 [*] 2
 [*] 3
 [*] 4
 [*] 5
 [*] 6
 [*] 7
 [*] 8
 [*] 9
 [*] 10
 [*] 11
 [*] 12
 [*] 13
 [*] 14
 [*] 15
 [*] 16
 [*] 17
 [*] 18
 [*] 19
 [*] 20
 [*] 21
 [*] 22
 [*] 23
 [*] 24
 [*] 25
 [*] 26
 [*] 27
 [*] 28
 [*] 29
 [*] 30
 [*] 31
 [*] 32
 [*] 33
 [*] 34
 [*] 35
 [*] 36
 [*] 37
 [*] 38
 [*] 39
 [*] 40
 [*] 41
 [*] 42
 [*] 43
 [*] 44
 [*] 45
 [*] 46
 [*] 47
 [*] 48
 [*] 49
 [*] 50
 [*] 51
 [*] 52
 [*] 53
 [*] 54
 [*] 55
 [*] 56
 [*] 57
 [*] 58
 [*] 59
 [*] 60
 [*] 61
 [*] 62
 [*] 63
 [*] 64
 [*] 65
 [*] 66
 [*] 67
 [*] 68
 [*] 69
 [*] 70
 [*] 71
 [*] 72
 [*] 73
 [*] 74
 [*] 75
 [*] 76
 [*] 77
 [*] 78
 [*] 79
 [*] 80
 [*] 81
 [*] 82
 [*] 83
 [*] 84
 [*] 85
 [*] 86
 [*] 87
 [*] 88
 [*] 89
 [*] 90
 [*] 91
 [*] 92
 [*] 93
 [*] 94
 [*] 95
 [*] 96
 [*] 97
 [*] 98
 [*] 99
